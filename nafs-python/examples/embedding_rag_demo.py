#!/usr/bin/env python3
"""
NAFS-4 Complete Multi-Provider Demo

Supports 11+ LLM/Embedding Providers:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Provider        ‚îÇ Features                                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Together.ai     ‚îÇ LLM: Llama-3, Mixtral, Qwen  |  Embed: m2-bert, bge        ‚îÇ
‚îÇ Groq            ‚îÇ LLM: Llama-3.1, Mixtral (fast!)  |  Embed: ‚ùå              ‚îÇ
‚îÇ Fireworks       ‚îÇ LLM: Llama, Mixtral, Qwen  |  Embed: nomic, UAE            ‚îÇ
‚îÇ Voyage AI       ‚îÇ LLM: ‚ùå  |  Embed: voyage-3, voyage-code, voyage-law       ‚îÇ
‚îÇ Jina AI         ‚îÇ LLM: ‚ùå  |  Embed: jina-v3, jina-colbert, jina-clip        ‚îÇ
‚îÇ HuggingFace     ‚îÇ LLM: Mistral, Llama  |  Embed: all-MiniLM, bge, e5         ‚îÇ
‚îÇ Ollama          ‚îÇ LLM: llama3, mistral, phi  |  Embed: nomic, mxbai          ‚îÇ
‚îÇ Cohere          ‚îÇ LLM: command-r  |  Embed: embed-v3 (english/multilingual) ‚îÇ
‚îÇ OpenAI          ‚îÇ LLM: gpt-4, gpt-3.5  |  Embed: text-embedding-3-small/large‚îÇ
‚îÇ Anthropic       ‚îÇ LLM: claude-3  |  Embed: ‚ùå                                ‚îÇ
‚îÇ Azure OpenAI    ‚îÇ LLM: deployed models  |  Embed: deployed models            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Environment Variables (set ONE to select provider):
    TOGETHER_API_KEY      ‚Üí Together.ai
    GROQ_API_KEY          ‚Üí Groq (fastest LLM)
    FIREWORKS_API_KEY     ‚Üí Fireworks AI
    VOYAGE_API_KEY        ‚Üí Voyage AI (embeddings only)
    JINA_API_KEY          ‚Üí Jina AI (embeddings only)
    HUGGINGFACE_API_KEY   ‚Üí HuggingFace Inference
    OLLAMA_URL            ‚Üí Local Ollama (e.g., http://localhost:11434)
    COHERE_API_KEY        ‚Üí Cohere
    OPENAI_API_KEY        ‚Üí OpenAI
    ANTHROPIC_API_KEY     ‚Üí Anthropic
"""

import asyncio
import nafs
import os

async def main():
    print("=" * 75)
    print("üåê NAFS-4 Multi-Provider System")
    print("=" * 75)
    
    # Initialize
    orch = await nafs.Orchestrator.create()
    
    # Get provider info
    provider = orch.get_provider_name()
    embedding_models = orch.get_embedding_models()
    
    print(f"\nüéØ Active Provider: {provider.upper()}")
    
    # Show capabilities
    if embedding_models:
        print(f"\nüìä Available Embedding Models ({len(embedding_models)}):")
        for m in embedding_models[:6]:
            print(f"   ‚Ä¢ {m}")
        if len(embedding_models) > 6:
            print(f"   ... and {len(embedding_models) - 6} more")
    else:
        print(f"\n‚ö†Ô∏è  {provider} does not support embeddings")
    
    # Test embedding if available
    if embedding_models:
        test_text = "NAFS-4 cognitive architecture for autonomous AI agents."
        print(f"\nüìù Test Embedding:")
        print(f'   "{test_text[:50]}..."')
        
        try:
            embedding = await orch.embed(test_text)
            print(f"   ‚úÖ Success: {len(embedding)} dimensions")
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
        
        # Try setting a different model
        if len(embedding_models) >= 2:
            alt_model = embedding_models[1]
            print(f"\nüîÑ Switching to: {alt_model}")
            await orch.set_embedding_model(alt_model)
            
            try:
                embedding = await orch.embed(test_text)
                print(f"   ‚úÖ Success: {len(embedding)} dimensions")
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
    
    # Show all available providers
    print("\n" + "‚îÄ" * 75)
    print("üìã All Supported Providers:")
    print("‚îÄ" * 75)
    
    providers = [
        ("TOGETHER_API_KEY", "Together.ai", "LLM + Embeddings"),
        ("GROQ_API_KEY", "Groq", "LLM only (fastest)"),
        ("FIREWORKS_API_KEY", "Fireworks AI", "LLM + Embeddings"),
        ("VOYAGE_API_KEY", "Voyage AI", "Embeddings only"),
        ("JINA_API_KEY", "Jina AI", "Embeddings only"),
        ("HUGGINGFACE_API_KEY", "HuggingFace", "LLM + Embeddings"),
        ("OLLAMA_URL", "Ollama (local)", "LLM + Embeddings"),
        ("COHERE_API_KEY", "Cohere", "LLM + Embeddings"),
        ("OPENAI_API_KEY", "OpenAI", "LLM + Embeddings"),
        ("ANTHROPIC_API_KEY", "Anthropic", "LLM only"),
    ]
    
    for env_var, name, capabilities in providers:
        is_active = provider.lower() == name.lower().split()[0]
        marker = "‚Üí" if is_active else " "
        status = "‚úì" if os.environ.get(env_var) else " "
        print(f"   {marker} [{status}] {name:<20} ({capabilities})")
    
    print("\n" + "=" * 75)
    print("üí° Set an environment variable and restart to switch providers.")
    print("=" * 75)

if __name__ == "__main__":
    asyncio.run(main())
